# 关于感知器の学习报告
`@Author 黄元炫`  
`@Date 20200329`
[感知器的定义](#1) | [感知器的作用](#2) | [感知器的训练](#3)

```
神经元也叫做感知器。
```
~~打算从0开始深度学习了_(:з」∠)_~~
# <a id='1'>感知器的定义</a>
![感知器](https://upload-images.jianshu.io/upload_images/2256672-801d65e79bfc3162.png)
- **输入权值**   一个感知器可以接受多个输入x，每个输入上有一个权值Wi，此外还有一个***偏置项*** b，就是上图中的W0
- **激活函数**   所谓激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到
输出端。  感知器的激活函数有很多，比如***阶跃函数***
- **输出** 感知器的输出公式——y=f(W*x+b)

# <a id='2'>感知器的作用</a>
感知器能实现简单的布尔运算，甚至可以拟合任何的线性函数，任何线性分类或线性回归问题都可以用感知器来解决。

# <a id='3'>感知器的训练</a>
1. 权重项和偏置项的值通过感知器训练算法获得。

2. 感知器规则：
    - Wi ← Wi + ∆Wi     
    - ∆Wi=ŋ（t-y）xi 
    - b ← b + ∆b
    - ∆b=ŋ（t-y）
    - t是训练样本的实际值，一般称之为***label***。y是感知器的输出值，ŋ是一个称为学习效率的常数，其作用是控制每一步调整权的幅度。

- 感知器类的实现

      class Perceptron(object):
        def __init__(self, input_num, activator):
            '''
            初始化感知器，设置输入参数的个数，以及激活函数。
            激活函数的类型为double -> double
            '''
            self.activator = activator
            # 权重向量初始化为0
            self.weights = [0.0 for _ in range(input_num)]
            # 偏置项初始化为0
            self.bias = 0.0
        def __str__(self):
            '''
            打印学习到的权重、偏置项
            '''
            return 'weights\t:%s\nbias\t:%f\n' % (self.weights, self.bias)
        def predict(self, input_vec):
            '''
            输入向量，输出感知器的计算结果
            '''
            # 把input_vec[x1,x2,x3...]和weights[w1,w2,w3,...]打包在一起
            # 变成[(x1,w1),(x2,w2),(x3,w3),...]
            # 然后利用map函数计算[x1*w1, x2*w2, x3*w3]
            # 最后利用reduce求和
            return self.activator(
                reduce(lambda a, b: a + b,
                       map(lambda (x, w): x * w,  
                           zip(input_vec, self.weights))
                    , 0.0) + self.bias)
        def train(self, input_vecs, labels, iteration, rate):
            '''
            输入训练数据：一组向量、与每个向量对应的label；以及训练轮数、学习率
            '''
            for i in range(iteration):
                self._one_iteration(input_vecs, labels, rate)
        def _one_iteration(self, input_vecs, labels, rate):
            '''
            一次迭代，把所有的训练数据过一遍
            '''
            # 把输入和输出打包在一起，成为样本的列表[(input_vec, label), ...]
            # 而每个训练样本是(input_vec, label)
            samples = zip(input_vecs, labels)
            # 对每个样本，按照感知器规则更新权重
            for (input_vec, label) in samples:
                # 计算感知器在当前权重下的输出
                output = self.predict(input_vec)
                # 更新权重
                self._update_weights(input_vec, output, label, rate)
        def _update_weights(self, input_vec, output, label, rate):
            '''
            按照感知器规则更新权重
            '''
            # 把input_vec[x1,x2,x3,...]和weights[w1,w2,w3,...]打包在一起
            # 变成[(x1,w1),(x2,w2),(x3,w3),...]
            # 然后利用感知器规则更新权重
            delta = label - output
            self.weights = map(
                lambda (x, w): w + rate * delta * x,
                zip(input_vec, self.weights))
            # 更新bias
            self.bias += rate * delta
